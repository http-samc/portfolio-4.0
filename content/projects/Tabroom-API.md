---
title: Tabroom-API
description: A revolutionary API for scraping and parsing tabroom.com üîç
important: true
cover: null
tags:
    - API
    - Python
    - DataScience
---

## What's Tabroom?
Glad you asked. [Tabroom.com](https://tabroom.com) is widely regarded as the 'de facto' tournament hosting site for all divisions of high-school and collegiate debate. There are tens of thousands of debaters across the nation (and increasingly across the world) who actively participate in competitions on this site. Unfortunately, the record of their success is limited at best. This is largely due to Tabroom's fault - they fail to standardize and archive data. To achieve this goal, a site scraper is required.

## How does the Tabroom-API work?
1. A list of tournaments is created and stored in `data/tournInfo.json`.
    - We target bid tournaments, which are those that serve as qualifiers for the [Tournament of Champions](https://ci.uky.edu/UKDebate/gold-pf-bid-tournaments). This is because we don't want to target local debaters who aren't trying to be competitive and harm the experience for them.
2. All tournaments not marked as done are scraped in the following order:
    1. Preliminary Seeds & Records
    2. Elimination Round Placings (Final Places or Bracket)
    3. 'Individual Pages'
3. The data is condensed into a single tournament result file.
    - Each entry's individual page *should* contain the same information as the combination of their 'row' in the preliminary seed table and final places table. However, due to Tabroom's lax checking, this cross-referencing behavior was adopted in order to improve our accuracy.
4. Any new results are merged into the master set.
    1. Because we scrape Bid Tournaments, we also create a 'Bid List.md' file here in order to document which teams have bids to the Tournament of Champion.

## Use
1. Clone the repository: `$ git clone https://github.com/http-samc/tabroom-API.git`
2. Install the requirements: `$ pip install -r requirements.txt`
2. Read the [documentation](https://github.com/http-samc/tabroom-API/blob/main/DOCS.md) (generated by [@smrth/GenDoc](/projects/GenDoc))

## What I Learned
Generally, speaker point scores have been largely ignored due to reporting inconsistencies and unfair forced 'drops', where the highest and lowest speaker scores are automatically removed from a team's preliminary rounds (usually out of 5-7) in order to give a 'more realistic average' (called 1HL dropping). I knew that I wanted to provide a better representation of speaking ability, so in addition to including the raw averages, I used [NumPy](https://numpy.org/) to drop a variable amount of rounds based on an interquartile range factor of 2. This gives a more holistic representation of speaking ability.

This API revolves around [requests](https://pypi.org/project/requests/) to get information in the form of html from Tabroom, [BeautifulSoup](https://pypi.org/project/beautifulsoup4/) to parse and extract structured data from the html, and [json](https://docs.python.org/3/library/json.html) to write this data out of memory and into a `.json` file. I was certainly familiar with all of these libraries prior to starting this project, but I learned a **lot** more about their nuances, especially `BeautifulSoup`, during it.

I also had to learn how to translate statistics into code. More specifically, my partner [Adithya](linkedin.com/in/adithyav-/) created the factor we use to rank debaters: the [OTR Score](https://github.com/http-samc/tabroom-API/blob/main/RANKING_METHODOLOGY.md). This relatively complex formula needed to be translated into code, and keeping track of all the various parameters throughout the scraping and parsing proved to be a challenging feat. Ultimately though, a strictly structured dictionary helped keep everything together and enabled us to pull off thousands of OTR Score calculations without a hitch.

But perhaps the most important lesson I learned is that, in situaitons like these, redundancy is key. In theory, we could get away with only 2 requests per tournament: 1 for the prelims page and 1 for the finals page. However, that's what all the other APIs, like [TheDebateWatch](https://www.thedebatewatch.com/)'s, do. This just causes the inconsistencies from Tabroom to directly translate into their sites, defeating the purpose all together. Instead, we make ~200 requests per tournament, checking the prelims and finals pages **against** each team's individual results page in order to generate the correct results.